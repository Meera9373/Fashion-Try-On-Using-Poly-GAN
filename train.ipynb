{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install import-ipynb\n","import import_ipynb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ijTTL9UYpauc","executionInfo":{"status":"ok","timestamp":1647846551347,"user_tz":-330,"elapsed":5694,"user":{"displayName":"4161_RAJVEE PISEY","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitPUndZmxdh1zjUs25n4UrE_6KWeV_VGq1Agrz=s64","userId":"16158897112346213971"}},"outputId":"e3a57c83-32db-4488-9555-f92fbe75207d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting import-ipynb\n","  Downloading import-ipynb-0.1.3.tar.gz (4.0 kB)\n","Building wheels for collected packages: import-ipynb\n","  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-py3-none-any.whl size=2975 sha256=a96a9726d2d07644ab4bd8c87fbbd0efed77e988d9d487c53ccb8955fd5ec8df\n","  Stored in directory: /root/.cache/pip/wheels/b1/5e/dc/79780689896a056199b0b9f24471e3ee184fbd816df355d5f0\n","Successfully built import-ipynb\n","Installing collected packages: import-ipynb\n","Successfully installed import-ipynb-0.1.3\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wc3sEeNyoF0X","executionInfo":{"status":"ok","timestamp":1647850113286,"user_tz":-330,"elapsed":30723,"user":{"displayName":"4161_RAJVEE PISEY","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitPUndZmxdh1zjUs25n4UrE_6KWeV_VGq1Agrz=s64","userId":"16158897112346213971"}},"outputId":"c3c4be9c-6348-4d3f-e9a3-3727d21e7024"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","src = list(files.upload().values())[0]\n","#open('/content/dataloader.ipynb','r').read(src)\n","#import PolyDatasetShape, PolyDatasetStitch, PolyDatasetRefine\n","\n","with open('/content/dataloader.ipynb', \"r\") as file1:\n","  dataloader = file1.read()\n","  #from dataloader import PolyDatasetShape, PolyDatasetStitch, PolyDatasetRefine\n","\n","with open('/content/utils.ipynb', \"r\") as file2:\n","  utils = file2.read()\n","  #from utils import ReplayBuffer, weights_init_normal, LambdaLR\n","\n","with open('/content/models.ipynb', \"r\") as file3:\n","  models = file3.read()\n","  #from models import GeneratorCoarse, Discriminator"],"metadata":{"id":"Qinx-uvrs6n2","executionInfo":{"status":"ok","timestamp":1647850145270,"user_tz":-330,"elapsed":28527,"user":{"displayName":"4161_RAJVEE PISEY","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitPUndZmxdh1zjUs25n4UrE_6KWeV_VGq1Agrz=s64","userId":"16158897112346213971"}},"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":247},"outputId":"0be19d3f-ebd8-4827-a20b-9ff4ba70f51a"},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-3bc87225-9e56-47d5-8d80-2b40c1012caf\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-3bc87225-9e56-47d5-8d80-2b40c1012caf\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving dataloader.py to dataloader.py\n","Saving dataloader.ipynb to dataloader.ipynb\n","Saving models.py to models.py\n","Saving utils.py to utils.py\n","Saving utils.ipynb to utils.ipynb\n","Saving models.ipynb to models.ipynb\n"]}]},{"cell_type":"code","source":["dataloader = open('dataloader.ipynb', 'wb').write(src)\n","models = open('models.ipynb', 'wb').write(src)\n","utils = open('utils.ipynb', 'wb').write(src)"],"metadata":{"id":"Bwr-j_ORwg9g","executionInfo":{"status":"ok","timestamp":1647850151457,"user_tz":-330,"elapsed":529,"user":{"displayName":"4161_RAJVEE PISEY","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitPUndZmxdh1zjUs25n4UrE_6KWeV_VGq1Agrz=s64","userId":"16158897112346213971"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"VBqyG8oMmTJ0","executionInfo":{"status":"ok","timestamp":1647850163703,"user_tz":-330,"elapsed":9934,"user":{"displayName":"4161_RAJVEE PISEY","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitPUndZmxdh1zjUs25n4UrE_6KWeV_VGq1Agrz=s64","userId":"16158897112346213971"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9710a23b-14ca-4aca-f411-0e0d047a820c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["c\n","from dataloader import PolyDatasetShape, PolyDatasetStitch, PolyDatasetRefine\n","from models import GeneratorCoarse, Discriminator\n","from utils import ReplayBuffer, weights_init_normal, LambdaLR"]},{"cell_type":"code","source":["def get_opt():\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--j', type = int, default = 0) # number of workers used for loading data\n","    parser.add_argument('--b', type = int, default = 1) # batch size\n","    parser.add_argument(\"--dataroot\")#, default = \"Data\")\n","    parser.add_argument(\"--datamode\", default = \"Train\")\n","    parser.add_argument(\"--stage\", default = \"Refine\", help = 'Shape, Stitch, Refine')\n","    parser.add_argument(\"--data_list\", default = \"train_pairs.txt\")\n","    parser.add_argument(\"--radius\", type = int, default = 5) # skeleton width\n","    parser.add_argument(\"--grid_size\", type = int, default = 5)\n","    parser.add_argument('--lr', type = float, default = 0.0002, help = 'Initial Learning Rate')\n","    parser.add_argument(\"--display_count\", type = int, default = 1000)\n","    parser.add_argument(\"--save_count\", type = int, default = 100)\n","    parser.add_argument(\"--shuffle\", action ='store_true', help = 'Shuffle Input Data')\n","    parser.add_argument(\"--epochs\", type = int, default = 45)\n","    parser.add_argument(\"--input_channel\", type = int, default = 6)\n","    parser.add_argument(\"--decay_epoch\", type = int, default = 10)\n","    parser.add_argument('--results', type = str, default = 'Results', help = 'Save Results')\n","    parser.add_argument(\"--critic\", type = int, default = 10) # Number of times after which to update Discriminator.\n","    parser.add_argument(\"--save_model\", type = int, default = 2)\n","    parser.add_argument('-f')\n","    opt = parser.parse_args()\n","    return opt"],"metadata":{"id":"iBP_hbGOmcRT","executionInfo":{"status":"ok","timestamp":1647850165911,"user_tz":-330,"elapsed":4,"user":{"displayName":"4161_RAJVEE PISEY","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitPUndZmxdh1zjUs25n4UrE_6KWeV_VGq1Agrz=s64","userId":"16158897112346213971"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def train(opt, train_loader, netG, netD):\n","    epoch = 0\n","    n_epochs = opt.epochs\n","    decay_epoch = opt.decay_epoch\n","    batchSize = opt.b\n","    size = 128\n","    input_nc = opt.input_channel\n","    output_nc = 3\n","    lr = opt.lr\n","    if opt.stage != \"Refine\":\n","        nRow = 3\n","    else:\n","        nRow = 4\n","    \n","    criterion_GAN = torch.nn.MSELoss()\n","    criterion_identity = torch.nn.L1Loss()\n","\n","    optimizer_G = torch.optim.Adam(netG.parameters(),lr = lr, betas = (0.5, 0.999))\n","    optimizer_D = torch.optim.Adam(netD.parameters(), lr = lr, betas = (0.5, 0.999))\n","\n","    lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda = LambdaLR(n_epochs, epoch, decay_epoch).step)\n","    lr_scheduler_D = torch.optim.lr_scheduler.LambdaLR(optimizer_D, lr_lambda = LambdaLR(n_epochs, epoch, decay_epoch).step)\n","\n","    # Inputs & targets memory allocation\n","    Tensor = torch.cuda.FloatTensor\n","    input_A = Tensor(batchSize, input_nc, size, size)\n","    target_real = Variable(Tensor(batchSize).fill_(1.0), requires_grad = False)\n","    target_fake = Variable(Tensor(batchSize).fill_(0.0), requires_grad = False)\n","\n","    fake_buffer = ReplayBuffer()\n","    \n","    for epoch in range(0, n_epochs):\n","        gc.collect()\n","        Source = iter(train_loader)\n","        avg_loss_g = 0\n","        avg_loss_d = 0\n","        for i in range(0, len(train_loader)):\n","            netG.train()\n","            target_real = Variable(torch.ones(1, 1), requires_grad = False).cuda()\n","            target_fake = Variable(torch.zeros(1, 1), requires_grad = False).cuda()\n","            optimizer_G.zero_grad()\n","\n","            if opt.stage != \"Refine\":\n","                src, mask, style_img, target, gt_cloth, skel, cloth = Source.next()\n","                src, mask, style_img, target, gt_cloth, skel, cloth = Variable(src.cuda()), Variable(mask.cuda()), Variable(style_img.cuda()), \n","                Variable(target.cuda()), Variable(gt_cloth.cuda()), Variable(skel.cuda()), Variable(cloth.cuda())\n","            else:\n","                src, mask, style_img, target, gt_cloth, wrap, diff, cloth = Source.next()\n","                src, mask, style_img, target, gt_cloth, wrap, diff, cloth = Variable(src.cuda()), Variable(mask.cuda()), Variable(style_img.cuda()), \n","                Variable(target.cuda()), Variable(gt_cloth.cuda()), Variable(wrap.cuda()), Variable(diff.cuda()), Variable(cloth.cuda())\n","\n","            # Inverse identity\n","            if opt.stage == \"Shape\":\n","                gen_targ,_,_,_,_,_,_ = netG(skel, cloth) # src,conditions\n","            elif opt.stage == \"Stitch\":\n","                gen_targ,_,_,_,_,_,_ = netG(src, style_img, skel)\n","            elif opt.stage == \"Refine\":\n","                gen_targ,_,_,_,_,_,_ = netG(diff, wrap)\n","                \n","            pred_fake = netD(gen_targ)\n","            \n","            if opt.stage == \"Shape\":\n","                loss_GAN = 10 * criterion_GAN(pred_fake, target_real) + 10 * criterion_identity(gen_targ, gt_cloth)\n","            elif opt.stage == \"Stitch\" or opt.stage == \"Refine\":\n","                loss_GAN = 10 * criterion_GAN(pred_fake, target_real) + 10 * criterion_identity(gen_targ, target)\n","\n","            loss_G = loss_GAN\n","            loss_G.backward()\n","\n","            optimizer_G.step()        \n","            #############################################\n","            optimizer_D.zero_grad()\n","\n","            if opt.stage == \"Shape\":\n","                pred_real = netD(gt_cloth)\n","            elif opt.stage == \"Stitch\" or opt.stage == \"Refine\":\n","                pred_real = netD(target)\n","            \n","            loss_D_real = criterion_GAN(pred_real, target_real)\n","\n","            # Fake loss\n","            gen_targ = fake_buffer.push_and_pop(gen_targ)\n","            pred_fake = netD(gen_targ.detach())\n","            loss_D_fake = criterion_GAN(pred_fake, target_fake)\n","\n","            # Total loss\n","            loss_D = (loss_D_real + loss_D_fake) * 0.5\n","            loss_D.backward()\n","            if (i + 1) % opt.critic == 0:\n","                optimizer_D.step()\n","\n","            avg_loss_g = (avg_loss_g + loss_G) / (i+1) \n","            avg_loss_d = (avg_loss_d + loss_D) / (i+1) \n","\n","            if (i + 1) % 100 == 0:\n","                print(\"Epoch: (%3d) (%5d/%5d) Loss: (%0.0003f) (%0.0003f)\" % (epoch, i + 1, len(train_loader), avg_loss_g * 1000, avg_loss_d * 1000))\n","\n","\n","            if (i + 1) % opt.display_count == 0:  \n","                if opt.stage == \"Shape\":\n","                    pic = (torch.cat([style_img, gen_targ, cloth, skel, target, gt_cloth], dim = 0).data + 1) / 2\n","                elif opt.stage == \"Stitch\":\n","                    pic = (torch.cat([src, gen_targ, cloth, skel, target, gt_cloth], dim = 0).data + 1) / 2\n","                elif opt.stage == \"Refine\":\n","                    pic = (torch.cat([wrap, diff, gen_targ, target], dim = 0).data + 1) / 2\n","                save_dir = \"{}/{}\".format(os.getcwd(), opt.results)\n","                os.mkdir(save_dir)\n","                save_image(pic, '%s/Epoch_(%d)_(%dof%d).jpg' % (save_dir, epoch, i + 1, len(train_loader)), nrow = nRow)\n","        if (epoch + 1) % opt.save_model == 0:\n","            save_dir = \"{}/{}\".format(os.getcwd(), opt.results)\n","            torch.save(netG.state_dict(), '{}/Gan_{}.pth'.format(save_dir, epoch))\n","        # Update learning rates\n","        lr_scheduler_G.step()\n","        lr_scheduler_D.step()"],"metadata":{"id":"9p_3VLo_mfjO","executionInfo":{"status":"ok","timestamp":1647850169387,"user_tz":-330,"elapsed":680,"user":{"displayName":"4161_RAJVEE PISEY","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitPUndZmxdh1zjUs25n4UrE_6KWeV_VGq1Agrz=s64","userId":"16158897112346213971"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def main():\n","    opt = get_opt()\n","    print(opt)\n","    print(\"Start to train stage: %s\" % (opt.stage))\n","        \n","    # create dataset \n","    if opt.stage == \"Shape\":\n","      dataset = PolyDatasetShape(128)\n","      train_loader = DataLoader(dataset, batch_size = opt.b, shuffle = False, num_workers = opt.j, drop_last = True, pin_memory = True)\n","                \n","    elif opt.stage == \"Stitch\":\n","        dataset = PolyDatasetStitch(128)\n","        train_loader = DataLoader(dataset, batch_size = opt.b, shuffle = False, num_workers = opt.j, drop_last = True, pin_memory = True)\n","\n","    elif opt.stage == \"Refine\":\n","      dataset = PolyDatasetRefine(128)\n","      train_loader = DataLoader(dataset, batch_size = opt.b, shuffle = False, num_workers = opt.j, drop_last = True, pin_memory = True)\n","   \n","    else:\n","      sys.exit(\"Please mention the Stage from [Shape, Stitch, Refine]\")\n","        \n","    if not os.path.exists(opt.results):\n","        os.makedirs(opt.results)\n","    netG = GeneratorCoarse(opt.input_channel, 3)\n","    netD = Discriminator()   \n","    # create model & train & save the final checkpoint\n","    netG.cuda()\n","    netD.cuda()\n","    netG.apply(weights_init_normal)\n","    netD.apply(weights_init_normal)    \n","    train(opt, train_loader, netG, netD)\n","    print('Finished training %s!' % (opt.stage))\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iiXFvhZ7mpB2","executionInfo":{"status":"ok","timestamp":1647850287856,"user_tz":-330,"elapsed":49973,"user":{"displayName":"4161_RAJVEE PISEY","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitPUndZmxdh1zjUs25n4UrE_6KWeV_VGq1Agrz=s64","userId":"16158897112346213971"}},"outputId":"fae6ddc0-39f4-4fcf-d35f-2dd59a52f043"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Namespace(b=1, critic=10, data_list='train_pairs.txt', datamode='Train', dataroot=None, decay_epoch=10, display_count=1000, epochs=45, f='/root/.local/share/jupyter/runtime/kernel-0f1ab72e-3751-43b1-a63d-bdf1582e664a.json', grid_size=5, input_channel=6, j=0, lr=0.0002, radius=5, results='Results', save_count=100, save_model=2, shuffle=False, stage='Refine')\n","Start to train stage: Refine\n","[] []\n"]},{"output_type":"stream","name":"stderr","text":["/content/utils.py:51: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n","  torch.nn.init.normal(m.weight.data, 0.0, 0.02)\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","Finished training Refine!\n"]}]},{"cell_type":"code","source":["\n"],"metadata":{"id":"9I5_3rd_jE3S","executionInfo":{"status":"ok","timestamp":1647850234862,"user_tz":-330,"elapsed":513,"user":{"displayName":"4161_RAJVEE PISEY","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitPUndZmxdh1zjUs25n4UrE_6KWeV_VGq1Agrz=s64","userId":"16158897112346213971"}}},"execution_count":7,"outputs":[]}]}